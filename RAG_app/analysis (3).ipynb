{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aZNt3YXJwF1"
      },
      "outputs": [],
      "source": [
        "%pip install crewai==0.28.8 crewai_tools==0.1.6 langchain-groq sentence-transformers langchain_huggingface langchain-openai langchain-community==0.0.29\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TGf2onEJ2Ed"
      },
      "outputs": [],
      "source": [
        "# üì• Import necessary packages and modules\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from crewai_tools import PDFSearchTool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from crewai_tools import tool\n",
        "from crewai import Crew\n",
        "from crewai import Task\n",
        "from crewai import Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQxrjAx9aYTc"
      },
      "outputs": [],
      "source": [
        "# üîê Load API keys\n",
        "GROQ_API_KEY='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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trFp-4Iian2T"
      },
      "outputs": [],
      "source": [
        "# üß† Set up the LLM model using Groq's Llama3\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "    openai_api_key=GROQ_API_KEY,\n",
        "    model_name=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNzTL9qxasfJ"
      },
      "outputs": [],
      "source": [
        "rag_tool = PDFSearchTool(pdf='doc.pdf',\n",
        "    config=dict(\n",
        "        llm=dict(\n",
        "            provider=\"groq\", # or google, openai, anthropic, llama2, ...\n",
        "            config=dict(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                api_key=GROQ_API_KEY,\n",
        "                # max_tokens=1000,\n",
        "                # temperature=0.5,\n",
        "                # top_p=1,\n",
        "                # stream=true,\n",
        "            ),\n",
        "        ),\n",
        "        embedder=dict(\n",
        "            provider=\"huggingface\", # or openai, ollama, ...\n",
        "            config=dict(\n",
        "                model=\"BAAI/bge-small-en-v1.5\",\n",
        "                #task_type=\"retrieval_document\",\n",
        "                # title=\"Embeddings\",\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqBP_Z6Xa8FW"
      },
      "outputs": [],
      "source": [
        "# üöÄ Query the RAG tool to perform document-based search\n",
        "rag_tool.run(\"What does Sporo Health do?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w50yu-LWcj67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "TAVILY_API_KEY='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'\n",
        "# Set Tavily API key as an environment variable\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
        "# üåê Set up Tavily tool for real-time web search\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezvu9FtgWKBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMBEF_C7c6cv"
      },
      "outputs": [],
      "source": [
        "#Run a web search using the Tavily tool\n",
        "web_search_tool.run(\"What does Sporo Health do?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42kS3W1idDby"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def router_tool(keywords):\n",
        "  \"\"\"Router Function\"\"\"\n",
        "\n",
        "\n",
        "  if 'Sporo Health' in keywords:\n",
        "    return 'vectorstore'\n",
        "  else:\n",
        "    return 'web_search'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8GOauihdKPe"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Define an AI agent with its role and toolset\n",
        "Router_Agent = Agent(\n",
        "  role='Router',\n",
        "  goal='Route user question to a vectorstore or web search',\n",
        "  backstory=(\n",
        "    \"You are an expert at routing a user question to a vectorstore or web search.\"\n",
        "    \"Use the vectorstore for questions on concept related to Retrieval-Augmented Generation.\"\n",
        "    \"You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use web-search.\"\n",
        "  ),\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnskFGEidPAw"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Define an AI agent with its role and toolset\n",
        "Retriever_Agent = Agent(\n",
        "role=\"Retriever\",\n",
        "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
        "backstory=(\n",
        "    \"You are an assistant for question-answering tasks.\"\n",
        "    \"Use the information present in the retrieved context to answer the question.\"\n",
        "    \"You have to provide a clear concise answer.\"\n",
        "),\n",
        "verbose=True,\n",
        "allow_delegation=False,\n",
        "llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiqB8c05dR5Q"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Define an AI agent with its role and toolset\n",
        "Grader_agent =  Agent(\n",
        "  role='Answer Grader',\n",
        "  goal='Filter out erroneous retrievals',\n",
        "  backstory=(\n",
        "    \"You are a grader assessing relevance of a retrieved document to a user question.\"\n",
        "    \"If the document contains keywords related to the user question, grade it as relevant.\"\n",
        "    \"It does not need to be a stringent test.You have to make sure that the answer is relevant to the question.\"\n",
        "  ),\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN-JIEzMdT0_"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Define an AI agent with its role and toolset\n",
        "hallucination_grader = Agent(\n",
        "    role=\"Hallucination Grader\",\n",
        "    goal=\"Filter out hallucination\",\n",
        "    backstory=(\n",
        "        \"You are a hallucination grader assessing whether an answer is grounded in / supported by a set of facts.\"\n",
        "        \"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVDm3IVAdWr-"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Define an AI agent with its role and toolset\n",
        "answer_grader = Agent(\n",
        "    role=\"Answer Grader\",\n",
        "    goal=\"Filter out hallucination from the answer.\",\n",
        "    backstory=(\n",
        "        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
        "        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
        "        \"If the answer is relevant generate a clear and concise response.\"\n",
        "        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool'\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Student task - new AI agent with new role\n",
        "\n",
        "evaluator = Agent(\n",
        "    role='Evaluator',\n",
        "    goal='Evaluate the performance of the other agents and refine the task',\n",
        "    backstory=(\n",
        "        \"You are an evaluator assessing the performance of the other AI agents and refining the task\"\n",
        "        \"You evaluate the output of the other AI agents and decide whether they have adequately performed their task\"\n",
        "        \"If the agents have performed their task well, proceed with the generated answer\"\n",
        "        \"If the agents have not performed their task well, generate a new anwer\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "jfYVIGVPtvZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdqOi9UCdZKj"
      },
      "outputs": [],
      "source": [
        "# üß© Define the task each agent is responsible for\n",
        "router_task = Task(\n",
        "    description=(\"Analyse the keywords in the question {question}\"\n",
        "    \"Based on the keywords decide whether it is eligible for a vectorstore search or a web search.\"\n",
        "    \"Use only a list of key words as as input for 'router_tool\"\n",
        "    \"If the router_tool returns vectorstore, return a single word 'vectorstore' if it is eligible for vectorstore search.\"\n",
        "    \"If the router_tool returns websearch, return a single word 'websearch' if it is eligible for web search.\"\n",
        "    \"Do not provide any other premable or explaination.\"\n",
        "    ),\n",
        "    expected_output=(\"Give a binary choice 'websearch' or 'vectorstore' based on the question\"\n",
        "    \"Do not provide any other premable or explaination.\"),\n",
        "    agent=Router_Agent,\n",
        "    tools=[router_tool],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRgO2FjfkJXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfmrdQQQdbne"
      },
      "outputs": [],
      "source": [
        "# üß© Define the task each agent is responsible for\n",
        "retriever_task = Task(\n",
        "    description=(\n",
        "    \"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n",
        "    \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n",
        "    \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"\n",
        "    ),\n",
        "    expected_output=(\"You should analyse the output of the 'router_task'\"\n",
        "    \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n",
        "    \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n",
        "    \"Return a clear and concise text as response.\"),\n",
        "    agent=Retriever_Agent,\n",
        "    context=[router_task],\n",
        "    #tools=[retriever_tool],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uruR6ozXddrh"
      },
      "outputs": [],
      "source": [
        "# üß© Define the task each agent is responsible for\n",
        "grader_task = Task(\n",
        "    description=(\"Based on the response from the retriever task for the question {question} evaluate whether the retrieved content is relevant to the question.\"\n",
        "    ),\n",
        "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\n",
        "    \"You must answer 'yes' if the response from the 'retriever_task' is in alignment with the question asked.\"\n",
        "    \"You must answer 'no' if the response from the 'retriever_task' is not in alignment with the question asked.\"\n",
        "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
        "    agent=Grader_agent,\n",
        "    context=[retriever_task],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH7urTAEdfZj"
      },
      "outputs": [],
      "source": [
        "# üß© Define the task each agent is responsible for\n",
        "hallucination_task = Task(\n",
        "    description=(\"Based on the response from the grader task for the quetion {question} evaluate whether the answer is grounded in / supported by a set of facts.\"),\n",
        "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the answer is sync with the question asked\"\n",
        "    \"Respond 'yes' if the answer is in useful and contains fact about the question asked.\"\n",
        "    \"Respond 'no' if the answer is not useful and does not contains fact about the question asked.\"\n",
        "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
        "    agent=hallucination_grader,\n",
        "    context=[grader_task],\n",
        ")\n",
        "\n",
        "# üß© Define the task each agent is responsible for\n",
        "answer_task = Task(\n",
        "    description=(\"Based on the response from the hallucination task for the quetion {question} evaluate whether the answer is useful to resolve the question.\"\n",
        "    \"If the answer is 'yes' return a clear and concise answer.\"\n",
        "    \"If the answer is 'no' then perform a 'websearch' and return the response\"),\n",
        "    expected_output=(\"Return a clear and concise response if the response from 'hallucination_task' is 'yes'.\"\n",
        "    \"Perform a web search using 'web_search_tool' and return ta clear and concise response only if the response from 'hallucination_task' is 'no'.\"\n",
        "    \"Otherwise respond as 'Sorry! unable to find a valid response'.\"),\n",
        "    context=[hallucination_task],\n",
        "    agent=answer_grader,\n",
        "    #tools=[answer_grader_tool],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define evaluator task\n",
        "evaluator_task = Task(\n",
        "    description =(\"Based on the outputs from prior tasks, evaluate the degree to which each agent has performed it's role\"),\n",
        "    expected_output=(\"Binary decision indicating whether the agents have performed their tasks adequately resulting in an acceptable answer\"\n",
        "    \"If decision is yes, respond with ONLY the answer generated by the 'answer_task'\"\n",
        "    \"There is no need to provide an explanation if the agents have performed well. Only return the final answer generated by 'answer_task'\"\n",
        "    \"Otherwise respond 'no' and suggest concise areas for improvement\"),\n",
        "    agent=evaluator,\n",
        "    context=[router_task, retriever_task, grader_task, hallucination_task, answer_task],\n",
        "    )"
      ],
      "metadata": {
        "id": "gsROrLmfvWaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS8gR0-HdhkX"
      },
      "outputs": [],
      "source": [
        "# üë• Assemble agents into a Crew to collaborate on the task\n",
        "rag_crew = Crew(\n",
        "    agents=[Router_Agent, Retriever_Agent, Grader_agent, hallucination_grader, answer_grader, evaluator],\n",
        "    tasks=[router_task, retriever_task, grader_task, hallucination_task, answer_task, evaluator_task],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZVdvcTqdjrz"
      },
      "outputs": [],
      "source": [
        "inputs ={\"question\":\"Does Sporo Health Streamline patient chart reviews?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox_RiAoGdrdr"
      },
      "outputs": [],
      "source": [
        "# ‚ñ∂Ô∏è Start the collaborative process among the agents\n",
        "result = rag_crew.kickoff(inputs=inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnyxIvotdvoU"
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_tool.add(\"/content/2410.15528v1.pdf\")\n",
        "#Add more contents to rag_tools's vectorstore"
      ],
      "metadata": {
        "id": "B9lpdxPtsncf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_tool.run(\"What is the focus of Sporo health?\")\n",
        "\n",
        "#Rag_tool.run acts as a similarity_search in this case. However for the purpose of learning I will also define\n",
        "#a vectorstore below and explore this"
      ],
      "metadata": {
        "id": "hdXdjZ7PbVji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare documents for vectorstore\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "#Load PDF and split into chunks\n",
        "loader = PyPDFLoader(\"/content/2410.15528v1.pdf\")\n",
        "doc = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(doc)\n",
        "\n",
        "#Repeat for other pdf\n",
        "loader_1 = PyPDFLoader(\"/content/doc.pdf\")\n",
        "doc_1 = loader_1.load_and_split()\n",
        "text_splitter_1 = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks_1 = text_splitter_1.split_documents(doc_1)\n"
      ],
      "metadata": {
        "id": "6wqFdqxycVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import FAISS\n",
        "%pip install faiss-cpu\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "juPKyrOadf_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialise vectorstore\n",
        "\n",
        "#Use HuggingFace\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "vectorstore = FAISS.from_documents(chunks, embedding_model)\n"
      ],
      "metadata": {
        "id": "8EGzR_HjdKz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform similarity search\n",
        "\n",
        "#Search query\n",
        "\n",
        "query = \"What is the focus of Sporo health?\"\n",
        "\n",
        "#Search for top 3 most relevant documents\n",
        "\n",
        "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "for doc in retrieved_docs:\n",
        "    # Print the first 300 characters of each document chunk\n",
        "    print(doc.page_content[:300], \"...\\n\")"
      ],
      "metadata": {
        "id": "b1EYxDN0pgl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "#\n",
        "#Perform PCA and visualise embeddings\n",
        "\n",
        "#Generate embeddings\n",
        "embeddings = embedding_model.embed_documents([doc.page_content for doc in chunks])\n",
        "#Perform PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(embeddings)\n",
        "\n",
        "print (pca_result)"
      ],
      "metadata": {
        "id": "-djDT9HfoYOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOkGw2sQZWnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(pca_result[:, 0], pca_result[:, 1])\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JBYnAlj3pg0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add new knowledge to knowledge base\n",
        "#Already proessed second PDF above\n",
        "\n",
        "vectorstore.add_documents(chunks_1)"
      ],
      "metadata": {
        "id": "hztiUt7FYA62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHLxIlg1pvLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test model with new queries\n",
        "\n",
        "query = \"What is the focus of Sporo health?\"\n",
        "\n",
        "#Search for top 3 most relevant documents\n",
        "\n",
        "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
        "for doc in retrieved_docs:\n",
        "    print(doc.page_content[:300])\n",
        "\n",
        "#Adding more to knowledge base has changed the result"
      ],
      "metadata": {
        "id": "Qi00au6Rqhxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new AI agent and add to crew - above\n"
      ],
      "metadata": {
        "id": "-ulfS_Crq2RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up capability for reporter to generate PHDs\n",
        "%pip install reportLab\n"
      ],
      "metadata": {
        "id": "TpNakJ-vp412"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import reportlab"
      ],
      "metadata": {
        "id": "7AojU744qMmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define tool for reporter agent to use\n",
        "\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "@tool\n",
        "def pdf_exporter(text):\n",
        "  \"\"\"PDF Exporter\"\"\"\n",
        "  doc = SimpleDocTemplate(\"output.pdf\", pagesize=letter)\n",
        "  styles = getSampleStyleSheet()\n",
        "  elements = []\n",
        "  for line in text.split(\"\\n\"):\n",
        "    elements.append(Paragraph(line, styles[\"Normal\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "  doc.build(elements)\n",
        "  return \"output.pdf\"\n",
        "\n"
      ],
      "metadata": {
        "id": "88Q4pxkkqH9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Report generator agent\n",
        "#Define the agent's job\n",
        "reporter = Agent(\n",
        "    role='Findings reporter',\n",
        "    goal='Collate the findings from a query into an easily digestible report',\n",
        "    backstory=(\n",
        "        \"You are a reporter, master at summarising complex information into an easily digestible form\"\n",
        "        \"You take results returned from vectorstores or web searches and collate them into easy-to-read documents\"\n",
        "        \"You work with retrieval and checking agents who will provide you with a checked and cleaned set of information to summarise\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    )\n",
        "reporter_task = Task(\n",
        "    description = (\"Collate the information returned by vectorstore or web searches into an easily readable format. \"\n",
        "                   \"Use the 'pdf_exporter' tool to return your findings as a PDF.\"\n",
        "                   \"Use the label 'text' as the input for the 'pdf_reporter' tool\"),\n",
        "    expected_output=(\"A PDF document summarising the key points of the vectorstore or web searches\"),\n",
        "    agent=reporter,\n",
        "    context=[answer_task],\n",
        "    tools=[pdf_exporter]\n",
        "    )"
      ],
      "metadata": {
        "id": "lrw42zdVyGAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjust other agents - if the reporter is going to summarise finding the retriever can be more liberable with the information they provide\n",
        "Retriever_Agent = Agent(\n",
        "role=\"Retriever\",\n",
        "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
        "backstory=(\n",
        "    \"You are an assistant for question-answering tasks.\"\n",
        "    \"Use the information present in the retrieved context to answer the question.\"\n",
        "    \"You have to provide a detailed answer.\"\n",
        "),\n",
        "verbose=True,\n",
        "allow_delegation=False,\n",
        "llm=llm,\n",
        ")\n",
        "\n",
        "retriever_task = Task(\n",
        "    description=(\"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n",
        "    \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n",
        "    \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"\n",
        "    ),\n",
        "    expected_output=(\"You should analyse the output of the 'router_task'\"\n",
        "    \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n",
        "    \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n",
        "    \"Return a clear and detailed as response.\"),\n",
        "    agent=Retriever_Agent,\n",
        "    context=[router_task],\n",
        "   #tools=[retriever_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "Xs6qFVfB0xus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a new answer grading agent specific to this task\n",
        "answer_grader = Agent(\n",
        "    role=\"Answer Grader\",\n",
        "    goal=\"Filter out hallucination from the answer.\",\n",
        "    backstory=(\n",
        "        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
        "        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
        "        \"If the answer is relevant, pass the response to the reporter to be summarised.\"\n",
        "        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool' and pass this to the reporter\"\n",
        "        \"There is no need to expound if the answer is relevant, simply pass it along\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")\n",
        "answer_task = Task(\n",
        "    description = (\"Evaluate the answer provided by the retriever task and decide whether it is relevant to answer the question\"\n",
        "    \"If the answer is relevant, pass it along to the reporter\"\n",
        "    \"If the answer is not relevant, perform a web search using 'web_search_tool' and pass this along instead\"),\n",
        "    agent = answer_grader,\n",
        "    context=[retriever_task],\n",
        "    expected_output=(\"If the answer provided by the retriever is relevant, output the entire answer\"\n",
        "    \"If the answer is not relevant, return a web search\"),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "mOtQpfN22gPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assemble new crew\n",
        "\n",
        "rag_crew = Crew(\n",
        "    agents=[Router_Agent, Retriever_Agent, answer_grader, reporter],\n",
        "    tasks=[router_task, retriever_task, answer_task, reporter_task],\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kd3veenV1zJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Query the crew\n",
        "\n",
        "inputs ={\"question\":\"Does Sporo Streamline patient chart reviews?\"}\n",
        "result = rag_crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "id": "IriKmvy02GIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (result)"
      ],
      "metadata": {
        "id": "sabVZ3vg4TSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}